# Memory Network with Associative Memory for Image-caption Ranking

## MSCOCO

* Preprocessed MSCOCO image-caption ranking dataset with tokenized captions and VGG-19 center features available at [[Train]](https://filebox.ece.vt.edu/~linxiao/github/mscoco-imcap-ranking/dataset_train.t7)[[Val]](https://filebox.ece.vt.edu/~linxiao/github/mscoco-imcap-ranking/dataset_val.t7)[[Test]](https://filebox.ece.vt.edu/~linxiao/github/mscoco-imcap-ranking/dataset_test.t7). The splits follow [Kiros et al.](https://github.com/ryankiros/visual-semantic-embedding) 82783/5000/5000.
* Val: 36.1/48.4 Image/Caption R@1
* Test: 36.1/49.6 Image/Caption R@1